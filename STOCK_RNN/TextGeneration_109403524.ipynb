{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRBvwrOM15OY"
      },
      "source": [
        "<img src=\"https://i.imgur.com/12tfKrD.png\" alt=\"Alin\">\n",
        "</img>\n",
        "\n",
        "\n",
        "# Demo RNN -- 張愛玲散文集AI二次創作\n",
        "\n",
        "資料集: 張愛玲繁體中文小說 《傳奇》\n",
        "\n",
        "爬蟲來源: [crawl_book](https://colab.research.google.com/drive/1f_HvQEvgkJPFc473TlA-I_3EmkThA2SR?usp=sharing)\n",
        "\n",
        "程式碼參考: [Tensorflow](https://www.tensorflow.org/tutorials/text/text_generation)\n",
        "\n",
        "本次資料集，著作權乃是張愛玲女士所擁有。**請勿將本次資料集散播、更改、用於非商業用途**。\n",
        "\n",
        "> **資料集說明**\n",
        "\n",
        "今年是張愛玲女士101年誕辰。張愛玲出生名門，曾就讀於香港大學和聖約翰大學，受過良好的中西教育。上海淪陷時期，陸續發表《沉香屑·第一爐香》、《傾城之戀》、《心經》、《金鎖記》等中、短篇小說，震動上海文壇。\n",
        "\n",
        "這次訓練取張愛玲散文集《傳奇》作為訓練，《傳奇》收留五篇散文: 「留情」、「鴻鸞禧」、「紅玫瑰與白玫瑰」、「等」、「桂花蒸阿小悲秋」。其中以「紅玫瑰與白玫瑰」最為膾炙人口。\n",
        "\n",
        "> **訓練步驟**\n",
        "\n",
        "深度學習在訓練模型上有以下幾個重要的步驟:\n",
        "1. 讀入相關封包\n",
        "2. 取得資料集 \n",
        "3. 資料前處理\n",
        "4. 建立模型\n",
        "5. 制定訓練計畫\n",
        "6. 評估模型\n",
        "7. 做預測\n",
        "\n",
        "> **本次模型介紹 RNN**\n",
        "\n",
        "![](https://i.imgur.com/FaY50C8.png)\n",
        "\n",
        "\n",
        "我們來看看維度，很多人會搞不懂RNN的維度:\n",
        "\n",
        "一個Seq通過RNN後的維度\n",
        "\n",
        "* Input: (Seq,${originDim}$)\n",
        "* RNN Neuron: 2048\n",
        "* Output: (Seq,2048) if (return_sequence == True) else (1,2048)\n",
        "![](https://i.imgur.com/9SVl6JR.png)\n",
        "\n",
        "![](https://i.imgur.com/z4ElFIr.png)\n",
        "\n",
        "> **把生成問題變成分類問題**\n",
        "\n",
        "![](https://i.imgur.com/TBHKuf6.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoKPksUD96Mb",
        "outputId": "8a7912f5-0ce9-45d9-8176-5297f49d2414"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=15z798g9flzYsYutT-q0Xuema7hknl-19\n",
            "To: /content/HP1.txt\n",
            "100% 462k/462k [00:00<00:00, 116MB/s]\n",
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1pPg4wNy_hr_9sgJu6KtA5OdutjGyNkj8\n",
            "To: /content/HP2.txt\n",
            "100% 500k/500k [00:00<00:00, 157MB/s]\n",
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1HUfW58ZoDg8GRiGSZ9MID6t8jRlNlJb_\n",
            "To: /content/HP3.txt\n",
            "100% 633k/633k [00:00<00:00, 121MB/s]\n",
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1lxVv_FeKxsfNsvrkLUNki9RDjtpRqgUi\n",
            "To: /content/HP4.txt\n",
            "100% 1.11M/1.11M [00:00<00:00, 168MB/s]\n",
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Mof57Fqklov9oLch6d-Du6Tvh364uk31\n",
            "To: /content/HP5.txt\n",
            "100% 1.45M/1.45M [00:00<00:00, 225MB/s]\n",
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1WFQfMyCl90UwGCaaYVEGwMCW_w13zYV-\n",
            "To: /content/HP6.txt\n",
            "100% 947k/947k [00:00<00:00, 165MB/s]\n",
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1fPdXYecoG-MztMQJp845AbwAhZAWQ_RZ\n",
            "To: /content/HP7.txt\n",
            "100% 1.09M/1.09M [00:00<00:00, 174MB/s]\n"
          ]
        }
      ],
      "source": [
        "# ****************************************\n",
        "# **請勿將本次資料集散播、用於非學術用途**\n",
        "# ****************************************\n",
        "\n",
        "# 執行即代表同意將會合法、合理使用資料集\n",
        "# 太多人同時存取可能會報cannot retrieve file error\n",
        "# 點擊you may still be able to access 下面那個連結再自行上傳檔案即可\n",
        "\n",
        "!gdown --id 15z798g9flzYsYutT-q0Xuema7hknl-19 --output \"./HP1.txt\"\n",
        "!gdown --id 1pPg4wNy_hr_9sgJu6KtA5OdutjGyNkj8 --output \"./HP2.txt\"\n",
        "!gdown --id 1HUfW58ZoDg8GRiGSZ9MID6t8jRlNlJb_ --output \"./HP3.txt\"\n",
        "!gdown --id 1lxVv_FeKxsfNsvrkLUNki9RDjtpRqgUi --output \"./HP4.txt\"\n",
        "!gdown --id 1Mof57Fqklov9oLch6d-Du6Tvh364uk31 --output \"./HP5.txt\"\n",
        "!gdown --id 1WFQfMyCl90UwGCaaYVEGwMCW_w13zYV- --output \"./HP6.txt\"\n",
        "!gdown --id 1fPdXYecoG-MztMQJp845AbwAhZAWQ_RZ --output \"./HP7.txt\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aEUrr67TzFb"
      },
      "source": [
        "## 1. 讀入Package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "pPCmAo0Q_G3i"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import os\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y550TvUGT9xv"
      },
      "source": [
        "## 2. 取得資料集"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Mbvzh_9_Tz8",
        "outputId": "fd0d9bc9-54f1-4349-f51b-93c1ecb11072"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "哈利波特全系列共有 2090906 字詞\n",
            "包含了 4141 個獨一無二的字 (含標點符號)\n",
            "\n",
            "第１章 大難不死的男孩\n",
            "家住水蠟樹街四號的德思禮夫婦總是得意地說他們是非常規矩的人家。拜託，拜託了。他們從來跟神秘古怪的事不沾邊，因為他們根本不相信那些邪門歪道。\n",
            "威農德思禮先生在一家名叫格朗寧的公司做主管，公司生產鑽機。他高大魁梧，胖得幾乎連脖子都沒了，卻蓄著一臉大鬍子。德思禮太太是個瘦削的金髮女人。她的脖子幾乎比正常人長一倍。這樣每當她花許多時間隔著籬牆引頸而望、窺探左鄰右舍時，她的長脖子可就派上了大用場。德思禮夫婦有一個小兒子，名叫達力。在他們看來，人世間沒有比達力更好的孩子了。\n",
            "德思禮一家什麼都不缺，但他們擁有一個秘密，他們最害怕的就是這秘密會被人發現。他們想，一旦有人發現波特一家的事，他們會承受不住的。波特太太是德思禮太太的妹妹，不過她們已經有好幾年不見面了。實際上，德思禮太太佯裝自己根本沒有這麼個妹妹，因為她妹妹和她那一無是處的妹夫與德思禮一家的為人處世完全不一樣。一想到鄰居們會說波特夫婦來到了，德思禮夫婦會嚇得膽顫心驚。他們知道波特也有個兒子，只是他們從來沒有見過。這孩子也是他們不與波特夫婦來往的一個很好的藉口，他們不願讓達力跟這種孩子廝混。\n",
            "我們的故事開始於一個晦暗、陰\n"
          ]
        }
      ],
      "source": [
        "# 作業之一就是試試看其他本小說\n",
        "\n",
        "book = \"\"\n",
        "with open(\"./HP1.txt\",\"r\",encoding=\"utf8\") as file:\n",
        "  for line in file:\n",
        "    book += line\n",
        "\n",
        "with open(\"./HP2.txt\",\"r\",encoding=\"utf8\") as file:\n",
        "  for line in file:\n",
        "    book += line\n",
        "\n",
        "with open(\"./HP3.txt\",\"r\",encoding=\"utf8\") as file:\n",
        "  for line in file:\n",
        "    book += line\n",
        "\n",
        "with open(\"./HP4.txt\",\"r\",encoding=\"utf8\") as file:\n",
        "  for line in file:\n",
        "    book += line\n",
        "\n",
        "with open(\"./HP5.txt\",\"r\",encoding=\"utf8\") as file:\n",
        "  for line in file:\n",
        "    book += line\n",
        "\n",
        "with open(\"./HP6.txt\",\"r\",encoding=\"utf8\") as file:\n",
        "  for line in file:\n",
        "    book += line\n",
        "\n",
        "with open(\"./HP7.txt\",\"r\",encoding=\"utf8\") as file:\n",
        "  for line in file:\n",
        "    book += line\n",
        "\n",
        "book_length = len(book)\n",
        "unique_words = set(book)\n",
        "print(f\"哈利波特全系列共有 {book_length} 字詞\")\n",
        "print(f\"包含了 {len(unique_words)} 個獨一無二的字 (含標點符號)\\n\")\n",
        "print(book[0:500])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Anv0UglDUQk2"
      },
      "source": [
        "## 3. 資料前處理\n",
        "\n",
        "文字前處理有一堆方法、作法:\n",
        "* 切字\n",
        "* 還原\n",
        "* 清除特殊字符\n",
        "* 清除不常見字符 (StopWord)\n",
        "\n",
        "\n",
        "我這裡僅使用去除不常見的字(StopWord)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "tQDQ8hxBEa6d"
      },
      "outputs": [],
      "source": [
        "# 計算字數統計\n",
        "words_count = {}\n",
        "for w in book:\n",
        "  if w in words_count:\n",
        "    words_count[w] += 1\n",
        "  else:\n",
        "    words_count[w] = 1\n",
        "\n",
        "words_count = sorted(words_count.items(),key=lambda x:x[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VT90O679Fe0T",
        "outputId": "377ae4ca-a2e0-43ee-b771-ce4940b3066b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "去除次數小於8的文字剩餘 : 3040\n"
          ]
        }
      ],
      "source": [
        "stop_word = 8\n",
        "unique_words = [w_tup[0] for w_tup in words_count if w_tup[1]>stop_word]\n",
        "print(f\"去除次數小於{stop_word}的文字剩餘 : {len(unique_words)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_uP5gOVIy2K",
        "outputId": "387e92f8-e67b-4f29-ba05-f14759d92132"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "原本哈利波特全系列共有 2090906 字詞\n",
            "去除不常出現的文字後\n",
            "剩餘2087281個字\n"
          ]
        }
      ],
      "source": [
        "print(f\"原本哈利波特全系列共有 {book_length} 字詞\")\n",
        "print(f\"去除不常出現的文字後\")\n",
        "book = [w for w in book if w in unique_words]\n",
        "print(f\"剩餘{len(book)}個字\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LP0BwFDAmcS",
        "outputId": "8f69baee-1de5-4fab-f600-0cd8ab9072bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "原始文字 : \n",
            "['第', '章', ' ', '大', '難', '不', '死', '的', '男', '孩', '\\n', '家', '住', '水', '蠟', '樹', '街', '四', '號', '的', '德', '思', '禮', '夫', '婦', '總', '是', '得', '意', '地', '說', '他', '們', '是', '非', '常', '規', '矩', '的', '人']\n",
            "----------------------------------------\n",
            "轉成index : \n",
            "{2434, 2826, 2188, 2703, 1819, 2720, 2467, 1832, 2733, 2735, 2996, 2997, 2616, 571, 2876, 3010, 1864, 3021, 3022, 2896, 3025, 2258, 3029, 3030, 2647, 2903, 2905, 3035, 3036, 3038, 2785, 2668, 2929, 2804, 2806, 2684, 2559}\n"
          ]
        }
      ],
      "source": [
        "# 文字轉數字(index)\n",
        "word_2_index = {word:index for index,word in enumerate(unique_words)}\n",
        "index_2_word = {word_2_index[word]:word for word in word_2_index}\n",
        "\n",
        "book_2_index = [word_2_index[w] for w in book]\n",
        "\n",
        "print(\"原始文字 : \")\n",
        "print(book[:40])\n",
        "print(\"-\"*40)\n",
        "print(\"轉成index : \")\n",
        "print({word_2_index[w] for w in book[:40]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "H-KDv4kqgxLH"
      },
      "outputs": [],
      "source": [
        "def ind2word_seq(seq):\n",
        "  return [index_2_word[i] for i in seq]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aDyjJymDmVv",
        "outputId": "8b8e83c0-517b-4d51-fa1e-7fb96ac73380"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(21,)\n",
            "tf.Tensor(\n",
            "[2806 2434 2467 2996 2684 3030 2876 3038 2668 2647 3035 2905 2896 2785\n",
            " 1864 2616 2258 2703 2188 3038 2735], shape=(21,), dtype=int32)\n",
            "['第', '章', ' ', '大', '難', '不', '死', '的', '男', '孩', '\\n', '家', '住', '水', '蠟', '樹', '街', '四', '號', '的', '德']\n",
            "(21,)\n",
            "tf.Tensor(\n",
            "[2826 2720 2903 1832 2559 3029 2997 2929 3022 3025 3036 3021 3029 2733\n",
            " 2804 1819  571 3038 3010 2905 3037], shape=(21,), dtype=int32)\n",
            "['思', '禮', '夫', '婦', '總', '是', '得', '意', '地', '說', '他', '們', '是', '非', '常', '規', '矩', '的', '人', '家', '。']\n"
          ]
        }
      ],
      "source": [
        "# 設定輸入模型長度\n",
        "seq_len = 20\n",
        "characters = tf.data.Dataset.from_tensor_slices(book_2_index)\n",
        "# characters = characters.map(lambda w:word_2_index[w.item()])\n",
        "\n",
        "sequences = characters.batch(seq_len+1,drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(2):\n",
        "  print(seq.shape)\n",
        "  print(seq)\n",
        "  print([index_2_word[i] for i in seq.numpy()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-dxqFkd7RU1"
      },
      "source": [
        "![](https://i.imgur.com/YMVMFEJ.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhFC16MdLONw",
        "outputId": "166307ad-36a8-4ce4-96fb-3e09e0ad795f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# 做input、target切割\n",
        "def split_input_target(seq):\n",
        "  input_txt = seq[:-1]\n",
        "  target_txt = seq[1:]\n",
        "  return input_txt,target_txt\n",
        "\n",
        "split_input_target(list(\"Tensorflow\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-O91DUM_uYV"
      },
      "source": [
        "![](https://i.imgur.com/YoHWLkf.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnJ4Bdj2gZ1V",
        "outputId": "89f32d31-c403-496b-bdd5-e1e4cd6c2e3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input : ['第', '章', ' ', '大', '難', '不', '死', '的', '男', '孩', '\\n', '家', '住', '水', '蠟', '樹', '街', '四', '號', '的']\n",
            "Target: ['章', ' ', '大', '難', '不', '死', '的', '男', '孩', '\\n', '家', '住', '水', '蠟', '樹', '街', '四', '號', '的', '德']\n",
            "--------------------------------------------------\n",
            "Input : [2806 2434 2467 2996 2684 3030 2876 3038 2668 2647 3035 2905 2896 2785\n",
            " 1864 2616 2258 2703 2188 3038]\n",
            "Target: [2434 2467 2996 2684 3030 2876 3038 2668 2647 3035 2905 2896 2785 1864\n",
            " 2616 2258 2703 2188 3038 2735]\n"
          ]
        }
      ],
      "source": [
        "dataset = sequences.map(split_input_target)\n",
        "\n",
        "for input_example,target_exaple in dataset.take(1):\n",
        "  print(\"Input :\", ind2word_seq(input_example.numpy()))\n",
        "  print(\"Target:\", ind2word_seq(target_exaple.numpy()))\n",
        "  print(\"-\"*50)\n",
        "  print(\"Input :\", input_example.numpy())\n",
        "  print(\"Target:\", target_exaple.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNivSh2Igr2-",
        "outputId": "c635bb23-19c1-434e-fdb5-100cd55f901a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset element_spec=(TensorSpec(shape=(64, 20), dtype=tf.int32, name=None), TensorSpec(shape=(64, 20), dtype=tf.int32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# 建立資料集\n",
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True))\n",
        "\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcDWKSbYUWWB"
      },
      "source": [
        "## 4. 建立模型\n",
        "\n",
        "![](https://i.imgur.com/TBHKuf6.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkRcSZAHnxlk",
        "outputId": "25bcffe9-9f5c-4f62-95b1-147cdbc15966"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 512)         1556480   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, None, 4096)        75513856  \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, None, 2048)        50339840  \n",
            "                                                                 \n",
            " dense (Dense)               (None, None, 3040)        6228960   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 133,639,136\n",
            "Trainable params: 133,639,136\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# 超參數\n",
        "EMBEDDING_DIM = 512\n",
        "\n",
        "# 使用 keras 建立一個非常簡單的 LSTM 模型\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "model.add(\n",
        "  tf.keras.layers.Embedding(\n",
        "    input_dim=len(unique_words), \n",
        "    output_dim=EMBEDDING_DIM\n",
        "))\n",
        "\n",
        "model.add(\n",
        "  tf.keras.layers.LSTM(\n",
        "    units=4096, \n",
        "    return_sequences=True, \n",
        "))\n",
        "\n",
        "model.add(\n",
        "  tf.keras.layers.LSTM(\n",
        "    units=2048, \n",
        "    return_sequences=True,\n",
        "))\n",
        "  \n",
        "model.add(\n",
        "  tf.keras.layers.Dense(\n",
        "      len(unique_words),activation=\"softmax\"))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKiszF5doFGz",
        "outputId": "718dc1b8-c011-42ca-8fb3-7e987fc3ee15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model input shape : (64, 20)\n",
            "Model output shape : (64, 20, 3040)\n",
            "Model target shape : (64, 20)\n"
          ]
        }
      ],
      "source": [
        "# 查看模型的輸入、輸出 shape\n",
        "for input_example,target_exaple in dataset.take(1):\n",
        "  predict_example = model(input_example)\n",
        "  print(f\"Model input shape : {input_example.shape}\")\n",
        "  print(f\"Model output shape : {predict_example.shape}\")\n",
        "  print(f\"Model target shape : {target_exaple.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsN6Zz4NReV4",
        "outputId": "bf9aca5a-b1a1-4455-c9c3-29dd4eac4d74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "原本的中文字序列：\n",
            "在他的幾個哥哥面前相形見，所以他看見自己\n",
            "----------------------------------------\n",
            "輸入尚未訓練的model後獲得：\n",
            "\n",
            "凶誹誹搓搓噁哆哆紹部部部部部總總總總城城\n"
          ]
        }
      ],
      "source": [
        "print(\"原本的中文字序列：\")\n",
        "[print(index_2_word[ind],end=\"\") for ind in input_example[0].numpy()]\n",
        "print()\n",
        "print(\"-\"*40)\n",
        "print(\"輸入尚未訓練的model後獲得：\")\n",
        "print()\n",
        "\n",
        "predict_words = tf.math.argmax(predict_example[0],-1)\n",
        "[print(index_2_word[ind],end=\"\") for ind in predict_words.numpy()]\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peEbrfDrUfuz"
      },
      "source": [
        "## 5. 制定訓練計畫並訓練\n",
        "\n",
        "* [sparse_categorical_crossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/sparse_categorical_crossentropy) V.S. [categorical_crossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/categorical_crossentropy)\n",
        "\n",
        "```python=\n",
        "# categorical_crossentropy\n",
        "y_true = [[0, 1, 0], [0, 0, 1]]\n",
        "y_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]]\n",
        "assert loss.shape == (2,)\n",
        "\n",
        "# sparse_categorical_crossentropy\n",
        "y_true = [1, 2]\n",
        "y_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]]\n",
        "assert loss.shape == (2,)\n",
        "\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "unPfQAQBonFj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07e17353-5e5d-4942-b65c-bf258b867f7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.16.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.16.1\n"
          ]
        }
      ],
      "source": [
        "!pip install -U tensorflow-addons\n",
        "import tensorflow_addons as tfa\n",
        "from keras import optimizers\n",
        "\n",
        "radam = tfa.optimizers.RectifiedAdam(0.001)\n",
        "ranger = tfa.optimizers.Lookahead(radam,sync_period=6,slow_step_size=0.5)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"adam\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IW5xiiMpJhJ",
        "outputId": "d30d5cdb-d33f-4610-d31f-7adc0499e91e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1553/1553 [==============================] - 254s 161ms/step - loss: 4.4751\n",
            "Epoch 2/20\n",
            "1553/1553 [==============================] - 251s 161ms/step - loss: 3.5201\n",
            "Epoch 3/20\n",
            "1553/1553 [==============================] - 250s 161ms/step - loss: 3.2127\n",
            "Epoch 4/20\n",
            "1553/1553 [==============================] - 250s 161ms/step - loss: 2.9939\n",
            "Epoch 5/20\n",
            "1553/1553 [==============================] - 250s 161ms/step - loss: 2.7881\n",
            "Epoch 6/20\n",
            "1553/1553 [==============================] - 250s 161ms/step - loss: 2.5768\n",
            "Epoch 7/20\n",
            "1553/1553 [==============================] - 250s 161ms/step - loss: 2.3486\n",
            "Epoch 8/20\n",
            "1553/1553 [==============================] - 250s 161ms/step - loss: 2.1054\n",
            "Epoch 9/20\n",
            "1553/1553 [==============================] - 250s 161ms/step - loss: 1.8534\n",
            "Epoch 10/20\n",
            "1553/1553 [==============================] - 250s 161ms/step - loss: 1.6025\n",
            "Epoch 11/20\n",
            "1553/1553 [==============================] - 250s 161ms/step - loss: 1.3674\n",
            "Epoch 12/20\n",
            "1553/1553 [==============================] - 250s 161ms/step - loss: 1.1610\n",
            "Epoch 13/20\n",
            "1553/1553 [==============================] - 250s 161ms/step - loss: 0.9896\n",
            "Epoch 14/20\n",
            "1553/1553 [==============================] - 251s 161ms/step - loss: 0.8550\n",
            "Epoch 15/20\n",
            "1553/1553 [==============================] - 250s 161ms/step - loss: 0.7551\n",
            "Epoch 16/20\n",
            "1553/1553 [==============================] - 250s 161ms/step - loss: 0.6850\n",
            "Epoch 17/20\n",
            "1553/1553 [==============================] - 252s 162ms/step - loss: 0.6327\n",
            "Epoch 18/20\n",
            "1553/1553 [==============================] - 251s 162ms/step - loss: 0.5973\n",
            "Epoch 19/20\n",
            "1553/1553 [==============================] - 251s 161ms/step - loss: 0.5684\n",
            "Epoch 20/20\n",
            "1553/1553 [==============================] - 251s 162ms/step - loss: 0.5467\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 20\n",
        "history = model.fit(\n",
        "    dataset, # 前面使用 tf.data 建構的資料集\n",
        "    epochs=EPOCHS,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-DD-OibUj64"
      },
      "source": [
        "## 6. 衡量模型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "xxbK80fXpOWD",
        "outputId": "4ddd1bb3-7461-4ac8-dec5-b36a7d00c615"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3elbMNg4z4N",
        "outputId": "9acbf439-352b-43f8-d38b-8e747eef3802"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "原本的中文字序列：\n",
            "事也會引起他們的注意。肯特郡下的那場流星\n",
            "----------------------------------------\n",
            "輸入進訓練後的model後獲得：\n",
            "\n",
            "，會回起他們的注意。他特郡下的那些傳星雨\n"
          ]
        }
      ],
      "source": [
        "after_train_predictions = model(input_example)\n",
        "after_sampled_indices = tf.argmax(after_train_predictions[0],1)\n",
        "\n",
        "print(\"原本的中文字序列：\")\n",
        "[print(index_2_word[ind],end=\"\") for ind in input_example[0].numpy()]\n",
        "print()\n",
        "print(\"-\"*40)\n",
        "print(\"輸入進訓練後的model後獲得：\")\n",
        "print()\n",
        "\n",
        "[print(index_2_word[ind],end=\"\") for ind in after_sampled_indices.numpy()]\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-ZgfcpVUpbc"
      },
      "source": [
        "## 7. 做預測\n",
        "\n",
        "![](https://i.imgur.com/YsOj6Mw.png)\n",
        "\n",
        "在實際生成文字時，我們會想要增加一些隨機性。比如”天天出去” 不加入隨機 “天天天天” 如果我們全部輸出的字都是取softmax最大可能性，則一個訓練完美的model會把整本書給輸出出來。但是我們要的是，希望電腦在最大可能性的幾個字中隨機挑選一個字出來。\n",
        "\n",
        "tf.random.categorical 會根據softmax機率後隨機挑選字，但是我們不希望因為模型很爛導致不合理的字被選中，因此我們會除上一個temperature來增加可能字的比重。\n",
        "\n",
        "EX: \"天天出去\" 預測下一個字\n",
        "1. 玩 : 0.3 \n",
        "2. 天 : 0.1 \n",
        "3. 浪 : 0.4 \n",
        "\n",
        "\"天\"有的機率被印出，我們不希望。所以我們可以在每一個機率除上一個temperature(0.01)\n",
        "1. 玩 : 30 \n",
        "2. 天 : 10 \n",
        "3. 浪 : 40 \n",
        "原本\"浪\"跟\"天\"差0.3，除temperature後差30\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "b3ryhOIg4-qB"
      },
      "outputs": [],
      "source": [
        "# 預測文字，並把預測文字循環當作下一次的輸入\n",
        "\n",
        "# 設定你的temperature\n",
        "temperature = 0.01\n",
        "\n",
        "def generateWords(input,words=500):\n",
        "  [print(index_2_word[ind],end=\"\") for ind in input]\n",
        "  for i in range(words):\n",
        "    next_input = tf.expand_dims(input,axis=0)\n",
        "    predicts = model(next_input)\n",
        "    predicts = predicts[:,-1,:]\n",
        "    predicts /= temperature\n",
        "    result = tf.random.categorical(\n",
        "        predicts,num_samples=1\n",
        "    )\n",
        "    chinese_ind = tf.squeeze(result).numpy()\n",
        "    print(index_2_word[chinese_ind],end=\"\")\n",
        "    input = input+[chinese_ind]\n",
        "    input = input[-seq_len:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-_4vCX4e3ZA"
      },
      "source": [
        "## 作業2.1 (30%)\n",
        "\n",
        "使用[爬蟲程式](https://colab.research.google.com/drive/1f_HvQEvgkJPFc473TlA-I_3EmkThA2SR?usp=sharing)來取得一個新的文本資料集，或是不管你從哪裡取得的資料集也可以(不要再張愛玲了，不限中英文)。然後丟入這個模型來看看AI生成文字的成果，將**結果**與**你的心得**(不是機器產生的心得)，貼上pdf。\n",
        "\n",
        "請隨意修改本colab的模型與參數來達到更好的結果。\n",
        "\n",
        "資料集越有趣越好，比如你可以去爬PTT文章來製作廢文產生器。去爬Dcard製作幻想文產生器。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7ELuAjW3rKW",
        "outputId": "65fa017a-4b0c-4c74-9c38-cff6c132063d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "葛林戴華德是同志嗎？」\n",
            "「當然，當然。」哈利說，想到了榮恩和妙麗，他自己和榮恩一起進了公共休息室。這裡所有的東西都由著他的頭，跟他哥哥的一樣蒼白。哈利不管在哪裡找到了這個地方，他自己也在一夜。」\n",
            "「我們必須返回他們的注意，」鄧不利多說，「不然我為什麼要找格里戈維奇。」\n",
            "「哦，是嗎？」阿不福思粗聲粗氣地問，「為什麼？」\n",
            "「我認為是你，」哈利說，「但我必須救點不許她分靈體，並救你們的信任，你必須知道。」\n",
            "「我？」\n",
            "「我想，他大概認為，魔法部的巫師來說，這是一本書的關心。」\n",
            "「你的魔杖在這兒，就在我們要面前，你就能——不著——」\n",
            "「不，」哈利堅決地說，「你必須等著，我們不會回去，去尋找佛地魔的，並遺憾地告訴我們，你是惟一能把他無意為麻瓜的法律的！」\n",
            "「鄧不利多！」哈利忍著笑向聲音發了一個燦爛的笑容。\n",
            "「你覺得這是個好主意，」哈利說道，「是個更優秀的巫師，更優秀的男子漢兒了……不可否認為哈利的內心在禁忌森林裡發生了什麼事，接著問道：「你能否認嗎？」\n",
            "「我認為不會把你算我的，哈利，」鄧不利多說，「所以，他只是感到很糟糕，可現實不過是個傲慢的光，此刻正聚在那一幕。\n",
            "「哈利，我想你不會去找那個房子吧，」花兒一邊幫比爾把枕頭塞進了哈利手裡，「她是史萊哲林的。」\n",
            "「他們會毀掉你，」榮恩一邊說，一邊順著梯子繼續給他們倆上樓，海格仰倒在他身邊。哈利把隱形斗篷緊緊裹在身上，看見馬份急切地、高爾平大的臉上洋溢著撕扯他的模樣。哈利確信龐芮夫人不在，她根本沒有想過兩個聽。他們三人在門口偵察一個不愉快的時候，在他們發現的秘密上訴巫師傳給巫師，那會不會是標準的：一旦進來了，一定是坐著沒有隱形的地方。哈利和妙麗瞪著他，臉上的笑容漸漸消失。\n",
            "「這不是偷，對嗎，露娜？」金妮問。\n",
            "「我們知道他在設法堵住了他，」哈利說，「我們也想盡自己的一份，」她朝贊諾皺著眉頭說，「你以為我知道自己在幹什麼……我們以為鄧不利多教授可以借給我們的東西，就是不相信他能力以為佛地魔會在殺戮咒上繼承來為什麼留現時，哈利的傷疤在傍晚的窗戶外停住了他，他滿臉困惑地盯著鄧不利多，而鄧不利多的臉一下子清晰地往後退去。\n",
            "「我只是試著猜一下萬應室，」榮恩說，「一直在仔細聽我們。」\n",
            "「什麼？」榮恩和妙麗一起問，聲音都啞了，「你媽媽要是那麼做的？」\n",
            "「不，應該不是，先生。我是麻瓜出身。」\n",
            "「赫－米－恩的記文，是嗎？」\n",
            "「是的。」哈利說。\n",
            "「不，不是，」金妮說著，聲音哽嚥了，「會開完了。」\n",
            "「好啊，但你待在這兒。」\n",
            "「你沒有魔杖——？」衛斯理先生問。\n",
            "「他們沒有聽見我的話嗎，波特？」念召喚咒的人大聲說，「怎麼樣，赫瑞司？」\n",
            "「哈利，我想我們該回去了，」路平說，「可是，你必須毫無其事地做一些事情。」\n",
            "「他已經在那裡了。」哈利說。\n",
            "「他們說他的名字就會說什麼，」榮恩最後說道，「如果你的魔藥課O．W．L．E．W．Ts課程，我們上節課交通堵塞，一旦密切注視著。」\n",
            "「說句實話，我認為這是關鍵的。」哈利說，「而且你要走了，快點兒給我幫著不祥的事，」穆敵氣憤地說，「你會跟他說的事實的呢？他說得對，天狼星肯定想當然地以為，他是自己報道的每一個字，最多那些巫師不可能死亡，當然，他是有觸覺的——」\n",
            "「它不會是石內卜的，」哈利說，「但我非做不可——」\n",
            "「『非做什麼咒語？」泰德馬上問，「什麼時候？」\n",
            "「它還封得很好，」穆敵說著對哈利咧嘴一笑，「非尼呀·耐吉會闖進去了？」\n",
            "「不要，不要，不要，不要，不要你這麼做，不是嗎？」\n",
            "「是的，」鄧不利多說，「佛地魔肯定會免她一死吧？」\n",
            "「我當然有，」榮恩說，一邊檢查著撕壞的牛奶大紙，「妙麗，如果你願意把我的話留到哪兒呢，你可以打賭——」\n",
            "「他當時在幾百米的高級人裡面超走了一個星期。我把阿不思·鄧不利多弄死了，就連天狼星也會逃出這個地方了。\n",
            "「哈利？」\n",
            "他掃視了一圈，發現哈利站在那兒，嘴唇蠕動著，好像沒有人能聽到任何聲音。他轉向哈利：「德達洛。\n",
            "「去去，武器走！」\n",
            "妙麗帶著他的生命在震動，他的心跳加快，像憤怒的樣子一樣感到刺痛。他站在那兒，呼哧呼哧喘著氣，渾身發抖。\n",
            "「我在新書館裡見過！」哈利叫道，可是怎麼也沒有說，只是又轉過身去看妙麗。他抬起頭看著她，只見她一邊踱步一邊仍然用那個不顧頭腦球表示它們。\n",
            "「好了，」麥教授說道，聲音顫抖著，好像被他所做的嚇人打破了似的，「我不知道是不是合法要做的！」\n",
            "「你做得很好，」穆敵說，「難道你已經知道飛賊裡藏著什麼危險？知不知道你並沒有什麼可笑的，我認為特裡勞妮教授給了他們一些中間，然後連根本沒有什麼風。哈利也舉起了魔杖。\n",
            "「你覺得很好玩，是嗎？」\n",
            "「哦，是的，」鄧不利多說，「如果你不能幫忙，我們就等一等。」\n",
            "他把紙包扔到榮恩床上，落到了自己的床上，就好像他希望有人陪他埋葬了。他從未體驗過那樣的痛苦。他現在必須在這座城堡周圍的警告團放慢慢地，他總覺得往鄧不利多的墳墓裡冒了幾百不夠—"
          ]
        }
      ],
      "source": [
        "init_seq = \"葛林戴華德是同志嗎\"\n",
        "init_seq_ind = [word_2_index[w] for w in init_seq]\n",
        "input = init_seq_ind[-seq_len:]\n",
        "\n",
        "generateWords(input,2000)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "TextGeneration-109403524.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}